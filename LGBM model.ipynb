{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polyphonic-cameroon",
   "metadata": {},
   "source": [
    "# Health Insurance Lead Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infrared-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressed-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>City_Code</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Accomodation_Type</th>\n",
       "      <th>Reco_Insurance_Type</th>\n",
       "      <th>Upper_Age</th>\n",
       "      <th>Lower_Age</th>\n",
       "      <th>Is_Spouse</th>\n",
       "      <th>Health Indicator</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C3</td>\n",
       "      <td>3213</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>X1</td>\n",
       "      <td>14+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11628.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C5</td>\n",
       "      <td>1117</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Joint</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>X2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>30510.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C5</td>\n",
       "      <td>3732</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Individual</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C24</td>\n",
       "      <td>4378</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Joint</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>No</td>\n",
       "      <td>X1</td>\n",
       "      <td>14+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>17780.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C8</td>\n",
       "      <td>2190</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>No</td>\n",
       "      <td>X2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>10404.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID City_Code  Region_Code Accomodation_Type Reco_Insurance_Type  Upper_Age  \\\n",
       "0   1        C3         3213            Rented          Individual         36   \n",
       "1   2        C5         1117             Owned               Joint         75   \n",
       "2   3        C5         3732             Owned          Individual         32   \n",
       "3   4       C24         4378             Owned               Joint         52   \n",
       "4   5        C8         2190            Rented          Individual         44   \n",
       "\n",
       "   Lower_Age Is_Spouse Health Indicator Holding_Policy_Duration  \\\n",
       "0         36        No               X1                     14+   \n",
       "1         22        No               X2                     NaN   \n",
       "2         32        No              NaN                     1.0   \n",
       "3         48        No               X1                     14+   \n",
       "4         44        No               X2                     3.0   \n",
       "\n",
       "   Holding_Policy_Type  Reco_Policy_Cat  Reco_Policy_Premium  Response  \n",
       "0                  3.0               22              11628.0         0  \n",
       "1                  NaN               22              30510.0         0  \n",
       "2                  1.0               19               7450.0         1  \n",
       "3                  3.0               19              17780.0         0  \n",
       "4                  1.0               16              10404.0         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading train data\n",
    "train_set = pd.read_csv('train.csv')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extended-oriental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>City_Code</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Accomodation_Type</th>\n",
       "      <th>Reco_Insurance_Type</th>\n",
       "      <th>Upper_Age</th>\n",
       "      <th>Lower_Age</th>\n",
       "      <th>Is_Spouse</th>\n",
       "      <th>Health Indicator</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50883</td>\n",
       "      <td>C1</td>\n",
       "      <td>156</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Individual</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50884</td>\n",
       "      <td>C4</td>\n",
       "      <td>7</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Joint</td>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "      <td>Yes</td>\n",
       "      <td>X1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>32204.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50885</td>\n",
       "      <td>C1</td>\n",
       "      <td>564</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>No</td>\n",
       "      <td>X3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17</td>\n",
       "      <td>9240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50886</td>\n",
       "      <td>C3</td>\n",
       "      <td>1177</td>\n",
       "      <td>Rented</td>\n",
       "      <td>Individual</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>No</td>\n",
       "      <td>X3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50887</td>\n",
       "      <td>C1</td>\n",
       "      <td>951</td>\n",
       "      <td>Owned</td>\n",
       "      <td>Individual</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>No</td>\n",
       "      <td>X3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>22534.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID City_Code  Region_Code Accomodation_Type Reco_Insurance_Type  \\\n",
       "0  50883        C1          156             Owned          Individual   \n",
       "1  50884        C4            7             Owned               Joint   \n",
       "2  50885        C1          564            Rented          Individual   \n",
       "3  50886        C3         1177            Rented          Individual   \n",
       "4  50887        C1          951             Owned          Individual   \n",
       "\n",
       "   Upper_Age  Lower_Age Is_Spouse Health Indicator Holding_Policy_Duration  \\\n",
       "0         30         30        No              NaN                     6.0   \n",
       "1         69         68       Yes               X1                     3.0   \n",
       "2         28         28        No               X3                     2.0   \n",
       "3         23         23        No               X3                     3.0   \n",
       "4         75         75        No               X3                     NaN   \n",
       "\n",
       "   Holding_Policy_Type  Reco_Policy_Cat  Reco_Policy_Premium  \n",
       "0                  3.0                5              11934.0  \n",
       "1                  3.0               18              32204.8  \n",
       "2                  4.0               17               9240.0  \n",
       "3                  3.0               18               9086.0  \n",
       "4                  NaN                5              22534.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dress-region",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40705, 13) (40705,)\n",
      "(10177, 13) (10177,)\n"
     ]
    }
   ],
   "source": [
    "# performing 80:20 train test split\n",
    "\n",
    "y = train_set['Response'].values\n",
    "X = train_set.drop('Response', axis=1)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-infrared",
   "metadata": {},
   "source": [
    "### Part 1 - Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "democratic-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurization(train_set, cv_set, test_set):\n",
    "    \n",
    "    '''\n",
    "    This function is taking dataframes and performing featurization on them.\n",
    "    Input : train dataframe, cross validation dataframe, test dataframe\n",
    "    Output: Featurized train dataframe, Featurized cv dataframe, Featurized test dataframe and unique column names (list)\n",
    "    '''\n",
    "    \n",
    "    # initializing a list to hold all the uniqe names as column\n",
    "    unique_words_bow = []\n",
    "    \n",
    "    ######################### for ID #########################\n",
    "    #########################        #########################\n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    id_vec_train = train_set['ID'].values\n",
    "    id_vec_train = id_vec_train[:, np.newaxis]\n",
    "\n",
    "    id_vec_cv = cv_set['ID'].values\n",
    "    id_vec_cv = id_vec_cv[:, np.newaxis]\n",
    "\n",
    "    id_vec_test = test_set['ID'].values\n",
    "    id_vec_test = id_vec_test[:, np.newaxis]\n",
    "\n",
    "    unique_words_bow.append('ID')\n",
    "    \n",
    "    ######################### for City_Code #########################\n",
    "    #########################               #########################\n",
    "    # to apply one hot encoding in categorical feature\n",
    "    city_vectorizer = CountVectorizer()\n",
    "    \n",
    "    # fit has to happen only on train data\n",
    "    city_vectorizer.fit(train_set['City_Code'].values) \n",
    "    \n",
    "    # we use the fitted CountVectorizer to convert the text to vector\n",
    "    train_city_ohe = city_vectorizer.transform(train_set['City_Code'].values)\n",
    "    cv_city_ohe = city_vectorizer.transform(cv_set['City_Code'].values)\n",
    "    test_city_ohe = city_vectorizer.transform(test_set['City_Code'].values)\n",
    "    \n",
    "    # getting all the names from the vectorizer\n",
    "    for val in city_vectorizer.get_feature_names():\n",
    "        unique_words_bow.append(val)\n",
    "    \n",
    "    \n",
    "    ######################### for Region_Code #########################\n",
    "    #########################                 #########################\n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    rc_vec_train = train_set['Region_Code'].values\n",
    "    rc_vec_train = rc_vec_train[:, np.newaxis]\n",
    "    \n",
    "    rc_vec_cv = cv_set['Region_Code'].values\n",
    "    rc_vec_cv = rc_vec_cv[:, np.newaxis]\n",
    "    \n",
    "    rc_vec_test = test_set['Region_Code'].values\n",
    "    rc_vec_test = rc_vec_test[:, np.newaxis]\n",
    "    \n",
    "    unique_words_bow.append('Region_Code')\n",
    "    \n",
    "    \n",
    "    ######################### for Accomodation_Type #########################\n",
    "    #########################                       #########################\n",
    "    # to apply one hot encoding in categorical feature\n",
    "    accomodation_vectorizer = CountVectorizer()\n",
    "    \n",
    "    # fit has to happen only on train data\n",
    "    accomodation_vectorizer.fit(train_set['Accomodation_Type'].values)\n",
    "    \n",
    "    # we use the fitted CountVectorizer to convert the text to vector\n",
    "    train_accomodation_ohe = accomodation_vectorizer.transform(train_set['Accomodation_Type'].values)\n",
    "    cv_accomodation_ohe = accomodation_vectorizer.transform(cv_set['Accomodation_Type'].values)\n",
    "    test_accomodation_ohe = accomodation_vectorizer.transform(test_set['Accomodation_Type'].values)\n",
    "    \n",
    "    # getting all the names from the vectorizer\n",
    "    for val in accomodation_vectorizer.get_feature_names():\n",
    "        unique_words_bow.append(val)\n",
    "\n",
    "        \n",
    "    ######################### for Reco_Insurance_Type #########################\n",
    "    #########################                         #########################\n",
    "    # to apply one hot encoding in categorical feature\n",
    "    reco_vectorizer = CountVectorizer()\n",
    "    \n",
    "    # fit has to happen only on train data\n",
    "    reco_vectorizer.fit(train_set['Reco_Insurance_Type'].values) \n",
    "    \n",
    "    # we use the fitted CountVectorizer to convert the text to vector\n",
    "    train_reco_ohe = reco_vectorizer.transform(train_set['Reco_Insurance_Type'].values)\n",
    "    cv_reco_ohe = reco_vectorizer.transform(cv_set['Reco_Insurance_Type'].values)\n",
    "    test_reco_ohe = reco_vectorizer.transform(test_set['Reco_Insurance_Type'].values)\n",
    "    \n",
    "    # getting all the names from the vectorizer\n",
    "    for val in reco_vectorizer.get_feature_names():\n",
    "        unique_words_bow.append(val)\n",
    "        \n",
    "    \n",
    "    ######################### for Upper_Age #########################\n",
    "    #########################               #########################\n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    ua_vec_train = train_set['Upper_Age'].values\n",
    "    ua_vec_train = ua_vec_train[:, np.newaxis]\n",
    "    \n",
    "    ua_vec_cv = cv_set['Upper_Age'].values\n",
    "    ua_vec_cv = ua_vec_cv[:, np.newaxis]\n",
    "    \n",
    "    ua_vec_test = test_set['Upper_Age'].values\n",
    "    ua_vec_test = ua_vec_test[:, np.newaxis]\n",
    "    \n",
    "    unique_words_bow.append('Upper_Age')\n",
    "    \n",
    "    \n",
    "    ######################### for Lower_Age #########################\n",
    "    #########################               #########################\n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    la_vec_train = train_set['Lower_Age'].values\n",
    "    la_vec_train = la_vec_train[:, np.newaxis]\n",
    "    \n",
    "    la_vec_cv = cv_set['Lower_Age'].values\n",
    "    la_vec_cv = la_vec_cv[:, np.newaxis]\n",
    "    \n",
    "    la_vec_test = test_set['Lower_Age'].values\n",
    "    la_vec_test = la_vec_test[:, np.newaxis]\n",
    "    \n",
    "    unique_words_bow.append('Lower_Age')\n",
    "    \n",
    "    \n",
    "    ######################### for Is_Spouse #########################\n",
    "    #########################               #########################\n",
    "    # to apply one hot encoding in categorical feature\n",
    "    spouse_vectorizer = CountVectorizer()\n",
    "    \n",
    "    # fit has to happen only on train data\n",
    "    spouse_vectorizer.fit(train_set['Is_Spouse'].values) \n",
    "    \n",
    "    # we use the fitted CountVectorizer to convert the text to vector\n",
    "    train_spouse_ohe = spouse_vectorizer.transform(train_set['Is_Spouse'].values)\n",
    "    cv_spouse_ohe = spouse_vectorizer.transform(cv_set['Is_Spouse'].values)\n",
    "    test_spouse_ohe = spouse_vectorizer.transform(test_set['Is_Spouse'].values)\n",
    "    \n",
    "    # getting all the names from the vectorizer\n",
    "    for val in spouse_vectorizer.get_feature_names():\n",
    "        unique_words_bow.append(val)\n",
    "\n",
    "    \n",
    "    ######################### for Health_indicator #########################\n",
    "    #########################                      #########################\n",
    "    # Since it is containing nan values so filling most frequently occured value\n",
    "    train_set['Health Indicator'] = train_set['Health Indicator'].fillna('X1')\n",
    "    cv_set['Health Indicator'] = cv_set['Health Indicator'].fillna('X1')\n",
    "    test_set['Health Indicator'] = test_set['Health Indicator'].fillna('X1')\n",
    "    \n",
    "    # to apply one hot encoding in categorical feature\n",
    "    health_indicator_vectorizer = CountVectorizer()\n",
    "    \n",
    "    # fit has to happen only on train data\n",
    "    health_indicator_vectorizer.fit(train_set['Health Indicator'].values) \n",
    "    \n",
    "    # we use the fitted CountVectorizer to convert the text to vector\n",
    "    train_health_indicator_ohe = health_indicator_vectorizer.transform(train_set['Health Indicator'].values)\n",
    "    cv_health_indicator_ohe = health_indicator_vectorizer.transform(cv_set['Health Indicator'].values)\n",
    "    test_health_indicator_ohe = health_indicator_vectorizer.transform(test_set['Health Indicator'].values)\n",
    "    \n",
    "    # getting all the names from the vectorizer\n",
    "    for val in health_indicator_vectorizer.get_feature_names():\n",
    "        unique_words_bow.append(val)\n",
    "        \n",
    "    \n",
    "    ######################### for Holding_Policy_Duration #########################\n",
    "    #########################                             #########################\n",
    "    # replacing values '14+' with '15'\n",
    "    train_set['Holding_Policy_Duration'] = train_set['Holding_Policy_Duration'].replace(to_replace='14+', value=15.0)\n",
    "    cv_set['Holding_Policy_Duration'] = cv_set['Holding_Policy_Duration'].replace(to_replace='14+', value=15.0)\n",
    "    test_set['Holding_Policy_Duration'] = test_set['Holding_Policy_Duration'].replace(to_replace='14+', value=15.0)\n",
    "    \n",
    "    # Since it is containing nan values so filling most frequently occured value\n",
    "    train_set['Holding_Policy_Duration'] = train_set['Holding_Policy_Duration'].fillna('1.0')\n",
    "    cv_set['Holding_Policy_Duration'] = cv_set['Holding_Policy_Duration'].fillna('1.0')\n",
    "    test_set['Holding_Policy_Duration'] = test_set['Holding_Policy_Duration'].fillna('1.0')\n",
    "    \n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    hpd_vec_train = train_set['Holding_Policy_Duration'].values\n",
    "    hpd_vec_train = hpd_vec_train[:, np.newaxis]\n",
    "    \n",
    "    hpd_vec_cv = cv_set['Holding_Policy_Duration'].values\n",
    "    hpd_vec_cv = hpd_vec_cv[:, np.newaxis]\n",
    "    \n",
    "    hpd_vec_test = test_set['Holding_Policy_Duration'].values\n",
    "    hpd_vec_test = hpd_vec_test[:, np.newaxis]\n",
    "    \n",
    "    unique_words_bow.append('Holding_Policy_Duration')\n",
    "    \n",
    "    \n",
    "    ######################### for Holding_Policy_Type #########################\n",
    "    #########################                         #########################\n",
    "    # Since it is containing nan values so filling most frequently occured value\n",
    "    train_set['Holding_Policy_Type'] = train_set['Holding_Policy_Type'].fillna(3)\n",
    "    cv_set['Holding_Policy_Type'] = cv_set['Holding_Policy_Type'].fillna(3)\n",
    "    test_set['Holding_Policy_Type'] = test_set['Holding_Policy_Type'].fillna(3)\n",
    "    \n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    hpt_vec_train = train_set['Holding_Policy_Type'].values\n",
    "    hpt_vec_train = hpt_vec_train[:, np.newaxis]\n",
    "    \n",
    "    hpt_vec_cv = cv_set['Holding_Policy_Type'].values\n",
    "    hpt_vec_cv = hpt_vec_cv[:, np.newaxis]\n",
    "    \n",
    "    hpt_vec_test = test_set['Holding_Policy_Type'].values\n",
    "    hpt_vec_test = hpt_vec_test[:, np.newaxis]\n",
    "    \n",
    "    unique_words_bow.append('Holding_Policy_Type')\n",
    "    \n",
    "    \n",
    "    ######################### for Reco_Policy_Cat #########################\n",
    "    #########################                     #########################\n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    rpc_vec_train = train_set['Reco_Policy_Cat'].values\n",
    "    rpc_vec_train = rpc_vec_train[:, np.newaxis]\n",
    "    \n",
    "    rpc_vec_cv = cv_set['Reco_Policy_Cat'].values\n",
    "    rpc_vec_cv = rpc_vec_cv[:, np.newaxis]\n",
    "    \n",
    "    rpc_vec_test = test_set['Reco_Policy_Cat'].values\n",
    "    rpc_vec_test = rpc_vec_test[:, np.newaxis]\n",
    "    \n",
    "    unique_words_bow.append('Reco_Policy_Cat')\n",
    "    \n",
    "    \n",
    "    ######################### for Reco_Policy_Premium #########################\n",
    "    #########################                         #########################\n",
    "    # converting column vector to row vector in train, cv and test\n",
    "    rpp_vec_train = train_set['Reco_Policy_Premium'].values\n",
    "    rpp_vec_train = rpp_vec_train[:, np.newaxis]\n",
    "    \n",
    "    rpp_vec_cv = cv_set['Reco_Policy_Premium'].values\n",
    "    rpp_vec_cv = rpp_vec_cv[:, np.newaxis]\n",
    "    \n",
    "    rpp_vec_test = test_set['Reco_Policy_Premium'].values\n",
    "    rpp_vec_test = rpp_vec_test[:, np.newaxis]\n",
    "    \n",
    "    unique_words_bow.append('Reco_Policy_Premium')\n",
    "    \n",
    "        \n",
    "    # combining (stacking, horizontally) all the matrices for train, test and cv\n",
    "    train_stack = np.hstack((id_vec_train, train_city_ohe.todense(), rc_vec_train, train_accomodation_ohe.todense(),\n",
    "                            train_reco_ohe.todense(), ua_vec_train, la_vec_train, train_spouse_ohe.todense(),\n",
    "                            train_health_indicator_ohe.todense(), hpd_vec_train, hpt_vec_train, rpc_vec_train, rpp_vec_train))\n",
    "    cv_stack = np.hstack((id_vec_cv, cv_city_ohe.todense(), rc_vec_cv, cv_accomodation_ohe.todense(),\n",
    "                            cv_reco_ohe.todense(), ua_vec_cv, la_vec_cv, cv_spouse_ohe.todense(),\n",
    "                            cv_health_indicator_ohe.todense(), hpd_vec_cv, hpt_vec_cv, rpc_vec_cv, rpp_vec_cv))\n",
    "    test_stack = np.hstack((id_vec_test, test_city_ohe.todense(), rc_vec_test, test_accomodation_ohe.todense(),\n",
    "                            test_reco_ohe.todense(), ua_vec_test, la_vec_test, test_spouse_ohe.todense(),\n",
    "                            test_health_indicator_ohe.todense(), hpd_vec_test, hpt_vec_test, rpc_vec_test, rpp_vec_test))\n",
    "\n",
    "    # returning results\n",
    "    return train_stack, cv_stack, test_stack, unique_words_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compact-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call\n",
    "\n",
    "tr, cv, te, unq = featurization(X_train, X_cv, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lucky-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40705, 59) (40705,)\n",
      "(10177, 59) (10177,)\n",
      "(21805, 59)\n"
     ]
    }
   ],
   "source": [
    "# getting shapes of results\n",
    "\n",
    "print(tr.shape, y_train.shape)\n",
    "print(cv.shape, y_cv.shape)\n",
    "print(te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "precious-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes\n",
    "\n",
    "ohe_train_data = pd.DataFrame(data=tr, columns=unq)\n",
    "ohe_cv_data = pd.DataFrame(data=cv, columns=unq)\n",
    "ohe_test_data = pd.DataFrame(data=te, columns=unq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complex-adoption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "\n",
    "ohe_train_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collaborative-venezuela",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "\n",
    "ohe_cv_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minor-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "\n",
    "ohe_test_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "painted-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving csv's\n",
    "\n",
    "ohe_train_data.to_csv('train_data.csv', index=False)\n",
    "ohe_cv_data.to_csv('cv_data.csv', index=False)\n",
    "ohe_test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "selective-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving labels\n",
    "\n",
    "np.savez_compressed(\"trainlabels.npz\", y_train)\n",
    "np.savez_compressed(\"cvlabels.npz\", y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-absolute",
   "metadata": {},
   "source": [
    "### Part 2 - Modeling (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "literary-briefs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>c1</th>\n",
       "      <th>c10</th>\n",
       "      <th>c11</th>\n",
       "      <th>c12</th>\n",
       "      <th>c13</th>\n",
       "      <th>c14</th>\n",
       "      <th>c15</th>\n",
       "      <th>c16</th>\n",
       "      <th>c17</th>\n",
       "      <th>...</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>9240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>15384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>17342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>14482.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  c1  c10  c11  c12  c13  c14  c15  c16  c17  ...  x4  x5  x6  x7  x8  \\\n",
       "0  48985   0    0    0    0    0    0    0    0    0  ...   0   0   0   1   0   \n",
       "1   6635   0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "2  25243   0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "3  42010   0    0    0    0    0    0    0    0    0  ...   1   0   0   0   0   \n",
       "4  19605   0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "\n",
       "   x9  Holding_Policy_Duration  Holding_Policy_Type  Reco_Policy_Cat  \\\n",
       "0   0                      2.0                  4.0               22   \n",
       "1   0                      4.0                  3.0               22   \n",
       "2   0                      5.0                  2.0               18   \n",
       "3   0                      1.0                  4.0               22   \n",
       "4   0                     15.0                  3.0               18   \n",
       "\n",
       "   Reco_Policy_Premium  \n",
       "0               9240.0  \n",
       "1              15384.0  \n",
       "2              19936.0  \n",
       "3              17342.0  \n",
       "4              14482.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading train data\n",
    "X_train = pd.read_csv('train_data.csv')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "respected-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>c1</th>\n",
       "      <th>c10</th>\n",
       "      <th>c11</th>\n",
       "      <th>c12</th>\n",
       "      <th>c13</th>\n",
       "      <th>c14</th>\n",
       "      <th>c15</th>\n",
       "      <th>c16</th>\n",
       "      <th>c17</th>\n",
       "      <th>...</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>30048.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "      <td>10476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17</td>\n",
       "      <td>15990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>12080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>17080.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  c1  c10  c11  c12  c13  c14  c15  c16  c17  ...  x4  x5  x6  x7  x8  \\\n",
       "0   4027   1    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "1  21417   0    0    0    0    1    0    0    0    0  ...   0   0   0   0   0   \n",
       "2  27830   1    0    0    0    0    0    0    0    0  ...   1   0   0   0   0   \n",
       "3  34896   0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "4  37010   0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "\n",
       "   x9  Holding_Policy_Duration  Holding_Policy_Type  Reco_Policy_Cat  \\\n",
       "0   0                     15.0                  1.0               19   \n",
       "1   0                      1.0                  3.0               21   \n",
       "2   0                      4.0                  4.0               17   \n",
       "3   0                      8.0                  3.0               18   \n",
       "4   0                      9.0                  4.0               22   \n",
       "\n",
       "   Reco_Policy_Premium  \n",
       "0              30048.0  \n",
       "1              10476.0  \n",
       "2              15990.0  \n",
       "3              12080.0  \n",
       "4              17080.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading cv data\n",
    "X_cv = pd.read_csv('cv_data.csv')\n",
    "X_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boring-lambda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading train labels\n",
    "y_train = np.load('trainlabels.npz')\n",
    "y_train = y_train['arr_0']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regulation-cargo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading cv labels\n",
    "y_cv = np.load('cvlabels.npz')\n",
    "y_cv = y_cv['arr_0']\n",
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "limited-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'ID' from train and cv dataset\n",
    "X_train = X_train.drop('ID', axis=1)\n",
    "X_cv = X_cv.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fantastic-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "param = {'objective' : 'binary', \n",
    "         'metric' : 'binary-logloss',\n",
    "         'num_leaves' : 31,\n",
    "         'boosting' : 'dart'}\n",
    "\n",
    "# creating Dataset for train and cross validation data\n",
    "train = lgb.Dataset(X_train, label=y_train)\n",
    "test = lgb.Dataset(X_cv, label=y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "royal-accent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9767, number of negative: 30938\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 40705, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239946 -> initscore=-1.152976\n",
      "[LightGBM] [Info] Start training from score -1.152976\n"
     ]
    }
   ],
   "source": [
    "# train lgb model\n",
    "lgb_model = lgb.train(param, train, num_boost_round=100, valid_sets=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving lgb model\n",
    "lgb_model.save_model('finalized_model_lgb.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "neutral-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading saved model\n",
    "lgb_model = lgb.Booster(model_file='finalized_model_lgb.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "valuable-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc_auc_score:  0.722053909752942\n",
      "test roc_auc_score:  0.6679687826746651\n"
     ]
    }
   ],
   "source": [
    "# predicting probabilities for X_train\n",
    "pred_train = lgb_model.predict(X_train)\n",
    "# calculating roc_auc_score\n",
    "print('train roc_auc_score: ', roc_auc_score(y_train, pred_train))\n",
    "\n",
    "# predicting probabilities for X_cv\n",
    "pred_cv = lgb_model.predict(X_cv)\n",
    "# calculating roc_auc_score\n",
    "print('test roc_auc_score: ', roc_auc_score(y_cv, pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "normal-spider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c10</th>\n",
       "      <th>c11</th>\n",
       "      <th>c12</th>\n",
       "      <th>c13</th>\n",
       "      <th>c14</th>\n",
       "      <th>c15</th>\n",
       "      <th>c16</th>\n",
       "      <th>c17</th>\n",
       "      <th>c18</th>\n",
       "      <th>...</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>Holding_Policy_Duration</th>\n",
       "      <th>Holding_Policy_Type</th>\n",
       "      <th>Reco_Policy_Cat</th>\n",
       "      <th>Reco_Policy_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>32204.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17</td>\n",
       "      <td>9240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>22534.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c10  c11  c12  c13  c14  c15  c16  c17  c18  ...  x4  x5  x6  x7  x8  \\\n",
       "0   1    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "1   0    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "2   1    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "3   0    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "4   1    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   0   \n",
       "\n",
       "   x9  Holding_Policy_Duration  Holding_Policy_Type  Reco_Policy_Cat  \\\n",
       "0   0                      6.0                  3.0                5   \n",
       "1   0                      3.0                  3.0               18   \n",
       "2   0                      2.0                  4.0               17   \n",
       "3   0                      3.0                  3.0               18   \n",
       "4   0                      1.0                  3.0                5   \n",
       "\n",
       "   Reco_Policy_Premium  \n",
       "0              11934.0  \n",
       "1              32204.8  \n",
       "2               9240.0  \n",
       "3               9086.0  \n",
       "4              22534.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading test data\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "# dropping 'ID' from test set\n",
    "test_data = test_data.drop('ID', axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "homeless-denial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28966044, 0.30349629, 0.28169202, ..., 0.01430483, 0.24182427,\n",
       "       0.14445184])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating probabilites for test set\n",
    "test_pred = lgb_model.predict(test_data)\n",
    "#printing them\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unauthorized-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID\n",
       "0  50883\n",
       "1  50884\n",
       "2  50885\n",
       "3  50886\n",
       "4  50887"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading sample submission file\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "# dropping default class labels\n",
    "submit = submit.drop('Response', axis=1, inplace=False)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "focused-validity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50883</td>\n",
       "      <td>0.289660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50884</td>\n",
       "      <td>0.303496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50885</td>\n",
       "      <td>0.281692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50886</td>\n",
       "      <td>0.257208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50887</td>\n",
       "      <td>0.232433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Response\n",
       "0  50883  0.289660\n",
       "1  50884  0.303496\n",
       "2  50885  0.281692\n",
       "3  50886  0.257208\n",
       "4  50887  0.232433"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting predicted probabilities to Response field\n",
    "submit['Response'] = test_pred\n",
    "# getting head(top 5 rows)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "portable-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving best model to the disk\n",
    "submit.to_csv('submission_lgbm_second.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
